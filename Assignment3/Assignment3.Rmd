---
title: "Assignment 3 R Notebook"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
editor_options:
  markdown:
    wrap: 72
---

## Welcome to Assignment 3, Data Exploration

# Instructions:

Below we've transcribed the assignment instructions with corresponding
code blocks beneath each.

[üö®**Please note,**]{.underline}

-   With the exception of headers and the above, writing in the normal
    font is ours, and [**bold/underlined writing is copy-pasted from the
    instructions.**]{.underline}

-   Code blocks were directly excerpted, adapted, and reused from
    previously provided instructions / guidance. We do not believe this
    to be plagiarism and hope that in declaring it up front we
    demonstrate our honest intent. The sources used are found in the
    Assignment 2 instructions (which are transcribed fully in the
    Assignment 2 folder in our repo).

-   Task 5: Annotating tables, has been performed inline, in a more
    traditional notebook manner. We do not reserve the annotations for
    step 5 and instead hope to meet the criteria by elaborating on all
    provided images and tables adjacently to each.

-   ‚≠êÔ∏è Stars denote items corresponding directly to the rubric

1.  [**Load into R the expression data and matching metadata that you
    processed in Assignment 2.**]{.underline}

Please insert your data files in the data directory such that the single
folder from refine.bio containing the metadata TSV and main TSV file are
present in the immediate subdirectory. This can be downloaded from
google drive,
[here!](https://drive.google.com/file/d/1aOnupOgIn-b7rSoGdRflNBvpfQPcR5v5/view?usp=sharing "Download folder to be unzipped as subdirectory of Data!")

This next step loads data and annotation libraries per the instructions,
but does not attempt to transform our Gene column to the Entrez IDs as
this was unnecessary for downstream processing.

```{r include=FALSE}
# Mount requisite libraries, install clustering lib
library(dplyr)
library(tidyverse)
library(readr)
library(factoextra)

if(!require("ggplot2"))
  install.packages("ggplot2")
if(!require("ggalluvial"))
  install.packages("ggalluvial")

# Create the data folder if it doesn't exist
if (!dir.exists("data")) {
  dir.create("data")
}

# Define the file path to the plots directory
plots_dir <- "plots"

# Create the plots folder if it doesn't exist
if (!dir.exists(plots_dir)) {
  dir.create(plots_dir)
}

# Define the file path to the results directory
results_dir <- "results"

# Create the results folder if it doesn't exist
if (!dir.exists(results_dir)) {
  dir.create(results_dir)
}

# Define the file path to the data directory
data_dir <- file.path("data", "SRP075377")

# Declare the file path to the gene expression matrix file inside directory saved as `data_dir`
data_file <- file.path(data_dir, "SRP075377.tsv")

# Declare the file path to the metadata file inside the directory saved as `data_dir`
metadata_file <- file.path(data_dir, "metadata_SRP075377.tsv")

# Attach library for pipe (%>%)
library(magrittr)
```

```{r}
# Check that files exist and are usable.
file.exists(data_file)
file.exists(metadata_file)
```

```{r include=FALSE}
# Read in data and metadata TSV file and make Gene column into row names
metadata <- readr::read_tsv(metadata_file)
expression_df <- readr::read_tsv(data_file) %>%
  tibble::column_to_rownames("Gene")
```

1.  [**Unsupervised Analysis**]{.underline}
    a.  [**Subset your data to the 5,000 most variable
        genes**]{.underline}
    b.  [**Using that subset of the data, select and run a clustering
        algorithm from this list:**]{.underline}
        1.  [**K-means**]{.underline}
        2.  [**Hierarchical clustering (hclust)**]{.underline}
        3.  [**ConsensusClusterPlus**]{.underline}
        4.  [**PAM Clustering**]{.underline}
        5.  [**Gaussian Mixture Models**]{.underline}
    c.  [**Each student in your team should run a different clustering
        method (e.g., if there are 4 students\
        on the team, there should be results for 4 clustering methods in
        your assignment writeup).**]{.underline}
    d.  [**How many clusters did each method find?**]{.underline}
        a.  [**If you ran a method that requires you to select the
            number of clusters (k), how did changing this value change
            the results? Compare cluster membership at each k to
            investigate this.**]{.underline}
        b.  [**If you ran a method that selects k for you, describe why
            it chose that k.**]{.underline}
    e.  [**Rerun each clustering method using different numbers of
        genes. Try 10, 100, 1000, and 10000 genes.**]{.underline}
        a.  [**How did the number of genes affect
            clustering?**]{.underline}
        b.  [**Create an alluvial diagram (Sankey plot) to visualize how
            the different clustering setups\
            changed cluster memberships for each sample.
            ([https://cran.r](https://cran.r-)project.org/web/packages/ggalluvial/vignettes/ggalluvial.html)**]{.underline}

# 1A: Subsetting to Most Variable Genes

```{r include=FALSE}
# Calculate row variance
# üö® ConsensusClusterPlus suggests using MAD - median absolute deviation.
row_variances <- apply(expression_df, 1, mad)
expression_df$row_variance <- row_variances

# Sort by row variance
expression_df <- expression_df[order(row_variances, decreasing = TRUE), ]

# Remove the row variance columns
expression_df$row_variances <- NULL

# Keep quantities mentioned in part E
top_10 <- head(expression_df, 10)
top_100 <- head(expression_df, 100)
top_1000 <- head(expression_df, 1000)
top_5000 <- head(expression_df, 5000)
top_10000 <- head(expression_df, 10000)

top_10 <- as.data.frame(t(top_10))
top_100 <- as.data.frame(t(top_100))
top_1000 <- as.data.frame(t(top_1000))
top_5000 <- as.data.frame(t(top_5000))
top_10000 <- as.data.frame(t(top_10000))
```

# 1B:

## Rayyan - K-means

```{r INCLUDE=FALSE}
# compute ideal K for K-means clustering using the "elbow method" 

if(!require("purrr"))
  install.packages("purrr")

if(!require('factoextra'))
  install.packages('factoextra')

set.seed(123)
#Expect a delay, takes a bit
fviz_nbclust(top_5000, kmeans, k.max = 6, method = "wss")

# using the elbow method, the optimal number of clusters appears to be 2 (since this is around where the curve begins to flatten out most gently)
```

The elbow method visualized above reruns K-Means with different amounts
of clusters and visualizes how "Total within sum of square" decreases.
Whats that mean for us? The WSS metric explains proximity of points to
their centroid. Lower values mean tighter groupings. The elbow method
means we look for where the elbow in the curve occurs, picking a number
of clusters K that does not overfit the data, but also provides a
significant reduction in WSS compared to K-1 clusters. Here we choose 2
as optimal.

```{r}
#about 20 seconds
kmeans_result_5000_three <- kmeans(top_5000,3,iter.max = 10, nstart = 25)
kmeans_result_5000_four <- kmeans(top_5000,4,iter.max = 10, nstart = 25)
kmeans_result_5000_five <- kmeans(top_5000,5,iter.max = 10, nstart = 25)
```

```{r}
#About 30 seconds
fviz_cluster(kmeans_result_5000_four, data = top_5000, geom="point")
```

Above we can see how these 4 clusters look when displayed in a 2D graph
via PCA. This is a healthy "sanity-check" indicating our choice to use
four clusters (per elbow method) is indeed acceptable. The amount of
overlap seen in 3 and 1 is concerning but this is perhaps merely an
illusion of the 2D plane.

[**If you ran a method that requires you to select the number of
clusters (k), how did changing this value change the results? Compare
cluster membership at each k to investigate this.**]{.underline}

The K-means clustering method required me to select the number of
clusters. To determine the ideal "k", I utilized the "factoextra"
package to generate a graph showing the number of clusters versus the
total within the sum of square. Using the elbow method, I determined
that the optimal number of clusters was 2, and to test how changing the
value changed the results, ran the "kmeans" clustering command for a k
of 3,4, and 5 to determine how changing k changed the results.

Cluster membership at 3,4, and 5 was:

3 - 4358, 594, 48,

4 - 3878, 954, 147, 21

5 - 3806, 1003, 161, 20, 10

By assigning k of 3 as opposed to 5000, it achieved of a reduction in
sum of squares by 32.3%. At a k of 4, this rose greatly to 37.3% At a k
of 5, it rose only slightly to 39.9%. By looking at cluster membership
at k = 3,4,5, we can see that cluster membership does not change
drastically between 4 and 5. Between those 2 points, the top 3 largest
groups have largely the same numbers. Meanwhile, between a k of 3 and 4,
the top 3 largest groups have drastically different numbers. These data
together confirms the earlier elbow method, telling us that 4 is the
most ideal number of clusters.

```{r}
# rerun K-Means clustering method with different number of genes AND K values for the alluvial down the line
kmeans_result_10_three <- kmeans(top_10,3,iter.max = 10,nstart=25)
kmeans_result_10_four <- kmeans(top_10,4,iter.max = 10,nstart=25)
kmeans_result_10_five <- kmeans(top_10,5,iter.max = 10,nstart=25)
kmeans_result_100_three <- kmeans(top_100,3,iter.max = 10,nstart=25)
kmeans_result_100_four <- kmeans(top_100,4,iter.max = 10,nstart=25)
kmeans_result_100_five <- kmeans(top_100,5,iter.max = 10,nstart=25)
kmeans_result_1000_three <- kmeans(top_1000,3,iter.max = 10,nstart=25)
kmeans_result_1000_four <- kmeans(top_1000,4,iter.max = 10,nstart=25)
kmeans_result_1000_five <- kmeans(top_1000,5,iter.max = 10,nstart=25)
kmeans_result_10000_three <- kmeans(top_10000,3,iter.max = 10,nstart=25)
kmeans_result_10000_four <- kmeans(top_10000,4,iter.max = 10,nstart=25)
kmeans_result_10000_five <- kmeans(top_10000,5,iter.max = 10,nstart=25)

```

[**How did the number of genes affect clustering?**]{.underline}

Cluster Membership at 10, 100, 1000, and 10,000 (with a k of 4) was:

10 - 6, 2, 1, 1

100 - 80, 16, 2, 2

1000 - 810, 162, 18, 10

10,000 - 8296, 1517, 166, 21

Looking solely at cluster membership, it appears that each time the
number of genes increased by 10 times, membership in the 1,2nd, and 3rd
largest groups roughly followed the magnification as well. As the number
of genes increased, a reduction in sum of squares at a k of 4 was
calculated as 70.5%, 36.8%, 35.5,% and 39.1%.

```{r}
alluvialData <- data.frame(
  K3 = kmeans_result_10_three$cluster, 
  K4 = kmeans_result_10_four$cluster, 
  K5 = kmeans_result_10_five$cluster
)
ggplot(data = alluvialData, aes(axis1 = K3, axis2 = K4, axis3 = K5)) +
  geom_alluvium(aes(fill = K3)) +
  geom_stratum() +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme_minimal() +
  labs(title = "KMeans for 10 Genes at K=3,4,5")
```

The first of the alluvial plots here shows only 10 genes worth of data.
We can see how the genes in cluster 1 persist largely within the same
cluster, as do those in cluster 3. Therefore K-means seems to have
elected to separate cluster 2 instead, in the K=3 vs K=4 transition. K=4
--\> 5, we see cluster 2 again separated into 2 clusters. This is not
overwhelmingly insightful other than that the cluster 1 and cluster 3
from the initial run of K=2 must be pretty tight / robust.

```{r}
alluvialData <- data.frame(
  K3 = kmeans_result_100_three$cluster, 
  K4 = kmeans_result_100_four$cluster, 
  K5 = kmeans_result_100_five$cluster
)
ggplot(data = alluvialData, aes(axis1 = K3, axis2 = K4, axis3 = K5)) +
  geom_alluvium(aes(fill = K3)) +
  geom_stratum() +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme_minimal() +
  labs(title = "KMeans for 100 Genes at K=3,4,5")

```

Things get more complicated with more genes. The visualization now shows
that there is indeed some small scale separation that takes place.
Cluster 2 (cluster 1 in the previous graph) now becomes cluster 4 but
with some trailing off to 3 from K=2 --\> 3. Cluster 1 is no longer
quite so robust, nor cluster 3 (which presumably correspond to 2 and 3
in the N=10 graph above the current one), and instead each exibit
substantial bifurcation from K=4 to K=5.

```{r}
alluvialData <- data.frame(
  K3 = kmeans_result_1000_three$cluster, 
  K4 = kmeans_result_1000_four$cluster, 
  K5 = kmeans_result_1000_five$cluster
)
ggplot(data = alluvialData, aes(axis1 = K3, axis2 = K4, axis3 = K5)) +
  geom_alluvium(aes(fill = K3)) +
  geom_stratum() +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme_minimal() +
  labs(title = "KMeans for 1000 Genes at K=3,4,5")

```

Funnily enough bifurcation appears reduced in this graph relative to the
N=100 example. This is because far more genes are introduced, creating a
much more stable, monolithic cluster (2) that marginalizes cluster 3 and
reduces the appearance of bifurcation (when in reality there are likely
several sub-pixel slivers of 3 connecting it to other clusters from K=3
--\> 4 and 4/ 4/5 in the latter transition.

```{r}
alluvialData <- data.frame(
  K3 = kmeans_result_10000_three$cluster, 
  K4 = kmeans_result_10000_four$cluster, 
  K5 = kmeans_result_10000_five$cluster
)
ggplot(data = alluvialData, aes(axis1 = K3, axis2 = K4, axis3 = K5)) +
  geom_alluvium(aes(fill = K3)) +
  geom_stratum() +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme_minimal() +
  labs(title = "KMeans for 10,000 Genes at K=3,4,5")

```

Again, not much changes here. Same alluvial diagram, with significantly
more data creating very large clusters as a result.

# Sahas - Hierarchical Clustering (hclust)

[Note, \~1 minute runtime on Macbook Air M2 (known for CPU), expect
delay.]{.underline}

```{r}
# 5000 most variable genes Hierarchical Clustering
distance <- dist(top_5000, method = "euclidean")
hcluster  <- hclust(distance, method = "complete")
# 1 cluster
hcluster_result_5000_one <- cutree(hcluster, k = 1)
# 2 clusters
hcluster_result_5000_two <- cutree(hcluster, k = 2)
# 3 clusters 
hcluster_result_5000_three <- cutree(hcluster, k = 3)

# Visualize dendrogram
h <- plot(hcluster, cex = 0.8, hang = -1)
#rect.hclust(hcluster, k = 2, border = 2:5)

# If you ran a method that requires you to select the number of clusters (k), how did changing # this value change the results? Compare cluster membership at each k to investigate this.

# Visualize clusters
fviz_cluster(list(data = top_5000, cluster = hcluster_result_5000_one), geom = ("point"))
fviz_cluster(list(data = top_5000, cluster = hcluster_result_5000_two), geom = ("point"))
fviz_cluster(list(data = top_5000, cluster = hcluster_result_5000_three), geom = ("point"))
```

Here we can see the noticeable difference in cluster membership between
K=2 and K=3 - the points on the top right of the scatterplot here are
divided into two new groups while the lower leftmost cluster remains
untouched and continues to overlap with a few of the red points. Such is
the nature of hierarchical clustering - cluster allocation remains
static and is merely subidivided at each step. Picking a different K
value just cuts the tree lower, it does not rerun the algorithm and
inform us of a new optimal allocation, but instead tells us about which
cluster, at each step, when subdivided, maximally increases
discrimination (its greedy!). Therefore observing differences in cluster
membership yields little intrigue or insight.

Expect further delay (\~1 mins?)

```{r}
# 10 most variable genes Hierarchical Clustering
distance <- dist(top_10, method = "euclidean")
hclusterTop10  <- hclust(distance, method = "complete")
plot(hclusterTop10, cex = 0.8, hang = -1, labels = TRUE)
hcluster_result_10_two <- cutree(hclusterTop10, k = 2)

# 100 most variable genes Hierarchical Clustering
distance <- dist(top_100, method = "euclidean")
hclusterTop100  <- hclust(distance, method = "complete")
plot(hclusterTop100, cex = 0.8, hang = -1, labels = FALSE)
hcluster_result_100_two <- cutree(hclusterTop100, k = 2)

# 1000 most variable genes Hierarchical Clustering
distance <- dist(top_1000, method = "euclidean")
hclusterTop1000  <- hclust(distance, method = "complete")
plot(hclusterTop1000, cex = 0.8, hang = -1, labels = FALSE)
hcluster_result_1000_two <- cutree(hclusterTop1000, k = 2)

# 10000 most variable genes Hierarchical Clustering
distance <- dist(top_10000, method = "euclidean")
hclusterTop10000  <- hclust(distance, method = "complete")
plot(hclusterTop10000, cex = 0.8, hang = -1, labels = FALSE)
hcluster_result_10000_two <- cutree(hclusterTop10000, k = 2)
```

The dendrograms above help to illustrate the tree being produced by
running variations of hierarchical clustering. Of interest is the very
large offshoot of the majority of the genes segregated away from smaller
groups in the 10,000 gene dendrogram. This will have consequences on the
alluvial visuals below, and raises questions about logarithmically
scaling the width of the bands alluvial diagrams produce, rather than
linearly.

Due to the nature of hierarchical clustering making the alluvial
diagrams exceptionally disinteresting, we've opted to highlight only
alluvials at 10 genes and 10,000 genes but with more divisions (you're
more or less looking at a horizontal dendrogram...)

```{r}
hcluster_result_10_two <- cutree(hclusterTop10, k = 2)
hcluster_result_10_three <- cutree(hclusterTop10, k = 3)
hcluster_result_10_four <- cutree(hclusterTop10, k = 4)
hcluster_result_10_five <- cutree(hclusterTop10, k = 5)
hcluster_result_10000_two <- cutree(hclusterTop10000, k = 2)
hcluster_result_10000_three <- cutree(hclusterTop10000, k = 3)
hcluster_result_10000_four <- cutree(hclusterTop10000, k = 4)
hcluster_result_10000_five <- cutree(hclusterTop10000, k = 5)

alluvial_data <- data.frame(
  K2 = hcluster_result_10_two,
  K3 = hcluster_result_10_three,
  K4 = hcluster_result_10_four,
  K5 = hcluster_result_10_five
)

ggplot(data = alluvial_data, aes(axis1 = K2, axis2 = K3, axis3 = K4, axis4 = K5)) +
  geom_alluvium(aes(fill = K2)) +
  geom_stratum() +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme_minimal() +
  labs(title = "Hierarchical Clustering across different values of K at 10 genes")

alluvial_data <- data.frame(
  K2 = hcluster_result_10000_two,
  K3 = hcluster_result_10000_three,
  K4 = hcluster_result_10000_four,
  K5 = hcluster_result_10000_five
)

ggplot(data = alluvial_data, aes(axis1 = K2, axis2 = K3, axis3 = K4, axis4 = K5)) +
  geom_alluvium(aes(fill = K2)) +
  geom_stratum() +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme_minimal() +
  labs(title = "Hierarchical Clustering across different values of K at 10000 genes")
```

There are two diagrams here. The first shows how cluster 1 bifurcates in
the first step of the tree, then cluster 3, and then cluster 3 again
(into 3 and 5). The larger clusters that remain by the fourth column are
presumably some of the more tightly grouped ones, though by this point
we're creating single-gene groupings which mean very little. By
contrast, lets look at what happens when we visualize 10,000 genes...

You're probably thinking "that doesn't look right". Au contraire. If we
look at the dendrogram for 10,000 genes we see how the ensuing splits in
the hierarchy take place on the left side with one giant arm reaching to
the right. This is the "cluster 2" which is renamed to cluster 4 on the
final column by chance, but represents this large undivided branch of
the tree that is only subdivided later in the hierarchy.

# Michael - PAM Clustering

```{r}
library(cluster)

#Center data around median gene expressions in each row, without touching OG data. This came from the ConsensusClusterPlus guide, though "Scale" which the internet recommended for use with PAM would accomplish the same thing just with means instead of medians.
top_10m = sweep(top_10,1, apply(top_10,1,median,na.rm=T))
top_100m = sweep(top_100,1, apply(top_100,1,median,na.rm=T))
top_1000m = sweep(top_1000,1, apply(top_1000,1,median,na.rm=T))
top_5000m = sweep(top_5000,1, apply(top_5000,1,median,na.rm=T))
top_10000m = sweep(top_10000,1, apply(top_10000,1,median,na.rm=T))

#Takes quite a while at 10,000
k <- 3
pam_result_10_three <- pam(top_10m, k = k)
pam_result_100_three <- pam(top_100m, k = k)
pam_result_1000_three <- pam(top_1000m, k = k)
pam_result_5000_three <- pam(top_5000m, k = k)
pam_result_10000_three <- pam(top_10000m, k = k)
```

üö®The instructions linked to PAM suggested the use of a dissimilarity
matrix but I couldnt get fviz and other operations downstream to work
with it, so im just doing PAM the classic way (it generates the
dissimilarity matrix). I suspect this is why the run time is so
crippling. Please consider enjoying some popcorn or perhaps painting the
nearest surface before hitting run on this next cell, so that you may
enjoy some semblance of stimulation. Your RAM usage graph may also be
amusing to watch.

```{r}
#Let's compare K values:

cluster_counts <- table(pam_result_5000_three$clustering)
cluster_counts

pam_result_5000_four <- pam(top_5000m, k = 4)
cluster_counts <- table(pam_result_5000_four$clustering)
cluster_counts

pam_result_5000_five <- pam(top_5000m, k = 5)
cluster_counts <- table(pam_result_5000_five$clustering)
cluster_counts

pam_result_5000_six <- pam(top_5000m, k = 6)
cluster_counts <- table(pam_result_5000_six$clustering)
cluster_counts
```

```{r}
fviz_cluster(pam_result_5000_three, geom = "point")
fviz_cluster(pam_result_5000_four,  geom = "point")
fviz_cluster(pam_result_5000_five, geom = "point")
fviz_cluster(pam_result_5000_six, geom = "point")
```

We can see how membership changes above, at least in the two chosen
dimensions for the visualization (since we're operating on 1600
dimensional data). Indeed it seems that more clusters reduce the
overlap, but the extent to which they reduce the overlap is better
demonstrated through the sillhouette method shown below:

üö®[Note, takes \~4 minutes on macbook air M2.]{.underline}

```{r}
#Takes around 4 minutes on a macbook air M2
library(factoextra)
fviz_nbclust(top_5000m, pam, k.max = 6, verbose = TRUE, print.summary = TRUE, method = "silhouette")

#should identify 2 as optimal K value, which is a function of sillhouette score
```

The sillhouette method used above is looking at all the points resulting
from different K values of PAM, giving them a score (based on their
proximity to their assigned cluster and distance to other clusters), and
then averaging the score accross all points to determine a total score
that represents discrimination. We'd expect this to increase with more
clusters but alas it seems 2 clusters is locally optimal in effectively
segregating our genes.

Below I visualize the sillhouette score. We can see the genes in the two
clusters that overlap, they are relatively few (the part of the red and
blue chunk below 0). The dotted red line represents the average score,
which is excellent. The X axis is individual genes though I've removed
the label to keep things clean!

```{r}
pam_result_5000_two <- pam(top_5000m, k = 2, diss = TRUE)
fviz_silhouette(pam_result_top5000, label=FALSE)
```

Finally lets look at an alluvial. Since 10,000 for PAM is very
computationally expensive, I will instead show an alluvial at 5000 for
many K values.

```{r}

top_5000G <- top_5000 %>%
  tibble::rownames_to_column("Gene")
alluvialData <- data.frame(
  K2 = pam_result_5000_two$clustering, 
  K3 = pam_result_5000_three$clustering, 
  K4 = pam_result_5000_four$clustering,
  K5 = pam_result_5000_five$clustering,
  K6 = pam_result_5000_six$clustering
)

ggplot(
  data = alluvialData, 
  aes(axis1 = K2, axis2 = K3, axis3 = K4, axis4 = K5, axis5 = K6)
) +
  geom_alluvium(aes(fill = K6)) +
  geom_stratum() +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme_classic() +
  xlab("Amount of Clusters") +
  ylab("Gene Index") +
  labs(title = "PAM for 5000 Genes at K=2,3,4,5,6")
```

And what a beautiful alluvial it is. I've color coded the segments by
their distribution to the clusters in K=6 instead of K=2 as in the
earlier alluvials. The result is we can see very clearly how the initial
2 clusters are subdivided, such that by the time we get to K=6, no
exceptionally monolithic cluster remains. Of intrigue is cluster 5/6 in
K=4/5, which is utterly marginalized and yet elected by PAM as a
suitable and significantly isolatable set of points. Visualizing this
cluster in PCA seems like a good choice, and indeed, when visualized in
the plots earlier, we see the pink points as signficiant outliers. These
genes are likely very differentially expressed relative to all other
genes in the sample. Very interesting indeed. A lesson here is that the
marginalized groups of an alluvial are often intriguing, making it a
poor visualization for those interesting outliers (though they capture
macroscopic trends that are still surely significant and more likely to
be relevant to the disease or affliction we're usually trying to capture
in bioinformatics).

3.  Heatmaps and Dendrograms

    1.  Create a heatmap of the 5,000 genes used in clustering, with an
        annotation sidebar showing one set of clusters you identified
        from each clustering method and the sample groups from
        Assignment
        1.  You should have n+1 annotation columns, 1 per clustering
            method and 1 for the sample groups\
            in Assignment 1.
        2.  Either create a different heatmap for each method or include
            all in the same heatmap.
        3.  Include a legend and axis labels
        4.  Include row and column dendrograms

#3 K-Means Heatmap

#for this, we need to also have the sample groupings (diabetic,
non-diabetic AND pancreatic islets because we have to have all 5,000
genes)

#i am confused

```{r}
mat_100<- data.matrix(copy_100,rownames.force = FALSE)
ht = ComplexHeatmap::Heatmap(mat_100,heatmap_legend_param = list(
        title = "Expression", at = c(0, 50, 100,150)
    ),column_title = "Clustered Genes",show_column_names = FALSE,cluster_columns = TRUE,cluster_rows = TRUE)
ComplexHeatmap::draw(ht)

```

4.  Statistics

    1.  Does cluster membership correlate with the groups you chose in
        Assignment 1? Perform a chi-squared test of independence to
        statistically compare the two. Do this for each clustering
        result you identified -- include all versions per clustering
        approach. You are comparing your different clustering results.
    2.  Adjust all statistical test results for multiple hypothesis
        testing (p.adjust).
    3.  Create a table with statistical test results that includes
        adjusted and un-adjusted p-values.

5.  Write a short summary for each plot/table you created in this
    assignment. In 3-5 sentences for each, describe what you did, what
    parameters you used (if any) and an interesting result from it.

6.  As a team, fill out the team evaluation table below.

    ‚úÖ

7.  Combine all results into a single file, submit on Canvas. Make sure
    that all your code is added to your GitHub repository.

    ‚úÖ

### üö®üö®üö®üö®üö®üö®üö®üö®üö®Everything Below this Point is Assignment 2 (For reference) üö®üö®üö®üö®üö®üö®üö®üö®üö®

[Please insert your data files in the data directory such that the
single folder from refine.bio containing the metadata TSV and main TSV
file are present in the immediate subdirectory. This can be downloaded
from google drive,
[here!](https://drive.google.com/file/d/1aOnupOgIn-b7rSoGdRflNBvpfQPcR5v5/view?usp=sharing "Download folder to be unzipped as subdirectory of Data!")]{.underline}

[This next step loads data and annotation libraries per the
instructions, but does not attempt to transform our Gene column to the
Entrez IDs as this was unnecessary for downstream
processing.]{.underline}

How much variation do you see in the data? To answer these questions,
log-scale the data, calculate per-gene median expression ranges, then
make a density plot showing those results.

```{r include=FALSE}
#Log scale the data
logscaleData <- expression_df
logscaleData[, -1] <- log(logscaleData[, -1])
logscaleData$median = apply(logscaleData[, -1], 1, median)

#Create a function to find ranges per row
calculate_range <- function(row) {
  max_value <- max(row)
  min_value <- min(row)
  range_value <- max_value - min_value
  return(range_value)
}

#Apply this to find ranges
logscaleData$row_ranges <- apply(logscaleData[,-1], 1, calculate_range)
```

```{r}
justPlotThis <- dplyr::select(logscaleData, columns="Gene", "median", "row_ranges")
justPlotThis <- justPlotThis %>% 
  dplyr::rename(
    Genes = columns,
    Median = median,
    Range = row_ranges,
    )

plot(density(justPlotThis$Median), xlab="Median Expression Values", main="Density of Median Expression Values")
```

[The above density plot simply shows the density of the median values.
It is barely bimodal with a second group visible at just over 1, these
genes being the small group that is being expressed more than the
majority.]{.underline}

```{r}
# First let's install the requisite libraries.
    if (!("affy" %in% installed.packages())) {
      # Install this package if it isn't installed yet
      BiocManager::install("affy", update = FALSE)
    }
    
expression_df <- readr::read_tsv(data_file) %>%
  # Tuck away the Gene ID column as row names
  tibble::column_to_rownames("Gene")

library(scales)
library(affy)
myColors <- hue_pal()(4)

plotDensity(log(expression_df+1), col=rep(myColors, each=3),
            lty=c(1:ncol(logscaleData)), xlab='Log(count)',
            main='Expression Density Distribution')
```

[‚≠êÔ∏èDensity Plot Showing Variation in Each Gene's Expression]{.underline}

#### Summarize your findings.

[The majority of the genes show negative median log-scaled expression (0
to 1), simply implying minimal expression relative to other genes.
However, a group can be seen with values near 1-2. These imply that the
genes in this group are those which, relative to other genes gathered
from the pancreatic islet cells samples, are being expressed the most.
This stands against no particular control, however, and so does not
yield any meaningful conclusions of the genes at hand being diabetic,
but rather just genes that are expressed more.]{.underline}

```{r}
plot(density(justPlotThis$Range), xlab="Expression Value Ranges", main="Density of Expression Range Values")
```

[The range density plot shows an intriguing bimodal distribution. A
large group of genes has a minimal range, whereas the majority of the
genes fall close to a range of 3.5 (log scale) in expression between
samples. Genes with a low variability across all samples are not
interesting since this data set contains both diabetic and control
patients.]{.underline}

```{r include=FALSE}
#Cleanup
rm(justPlotThis)
rm(logscaleData)
rm(mapped_df)
rm(mapped_list)
rm(multi_mapped)
rm(myColors)
rm(calculate_range)
```

### 2. Now that you have loaded the expression data into R, generate a PCA plot:

-   If you have counts file(s), follow these DESeq2 directions to
    generate an expression matrix.
-   Use the DESeq2 function plotPCA() to generate your plot (see here)
-   Color your plot by the 2 groups you identified in assignment 1
    (e.g., Diabetic vs Non-Diabetic)
-   Make sure you include a legend and label the axes!

```{r include=FALSE}
# First let's install the requisite libraries.
if (!("DESeq2" %in% installed.packages())) {
  # Install this package if it isn't installed yet
  BiocManager::install("DESeq2", update = FALSE)
}

# Attach the DESeq2 library
library(DESeq2)
```

Alright, let's prep the metadata to better select what we need.

```{r include=FALSE}
new_expression_df <- readr::read_tsv(data_file) %>%
  tibble::column_to_rownames("Gene")

metadata <- metadata %>%
  dplyr::mutate(diabetes = dplyr::case_when(
    stringr::str_detect(refinebio_subject, "non t2d") ~ "reference",
    stringr::str_detect(refinebio_subject, "t2d") ~ "diabetic",
  ))

#Remove ambiguously-labeled samples from metadata
culledMeta <- metadata[!(metadata$refinebio_subject=="pancreatic islets"),]

discardColumns <- metadata[(metadata$refinebio_subject=="pancreatic islets"),]
discardColumns = as.vector(discardColumns$refinebio_accession_code)
length(discardColumns)
#Preserve only columns in expression_df that match one of the accession ids
culled_expression_df = new_expression_df[,!(names(new_expression_df) %in% discardColumns)]

# Make mutation_status a factor and set the levels appropriately
culledMeta <- culledMeta %>%
  dplyr::mutate(
    # Here we define the values our factor variable can have and their order.
    diabetes = factor(diabetes, levels = c("reference", "diabetic"))
  )
```

```{r}
round_culled_expression_df <- round(culled_expression_df)


ddset <- DESeqDataSetFromMatrix(
  # Here we supply non-normalized count data
  countData = round_culled_expression_df,
  # Supply the `colData` with our metadata data frame
  colData = culledMeta,
  # Supply our diabetes variable to `design`
  design = ~diabetes #Diabetes_status
)

dds_norm <- vst(ddset)

plotPCA(
  dds_norm,
  intgroup = "diabetes"
)

pca_results <-
  plotPCA(
    dds_norm,
    intgroup = c("diabetes"),
    returnData = TRUE # This argument tells R to return the PCA values
  )

ddset <- DESeqDataSetFromMatrix(
  # Here we supply non-normalized count data
  countData = round_culled_expression_df,
  # Supply the `colData` with our metadata data frame
  colData = culledMeta,
  # Supply our diabetes variable to `design`
  design = ~diabetes #Diabetes_status
)

dds_norm <- vst(ddset)

plotPCA(
  dds_norm,
  intgroup = "diabetes"
)

pca_results <-
  plotPCA(
    dds_norm,
    intgroup = c("diabetes"),
    returnData = TRUE # This argument tells R to return the PCA values
  )

```

[‚≠êÔ∏è PCA Plot Colored by Groups]{.underline}

-   PCA Plot Summary: [The PCA plot shows that the two groups diabetic
    and non-diabetic separate into two different clusters. The
    non-diabetic clusters tends to have less variance and is one uniform
    cluster while the diabetic samples are separated into two different
    uniform clusters that have more variance.]{.underline}

-   If you have 3 or 4 students in your group, also generate either
    t-SNE or UMAP plot, and summarize the differences and similarities
    between your two plots.

-   UMAP:

```{r}
library("umap")

gene <- DESeqDataSetFromMatrix(
  countData = round_culled_expression_df, # Counts values for all samples in our rounded dataset
  colData = culldMeta, #  Supply the `colData` with our metadata data frame
  design = ~diabetes #Supply our diabetes variable to `design`
  # Diabetes_status
)
gene_norm <- vst(gene)
normalized_counts <- assay(gene_norm) %>%
  t() # transpose this data so each row is a sample
umap_results <- umap::umap(normalized_counts)
umap_plot_df <- data.frame(umap_results$layout) %>%
  # Turn sample IDs from row names into a column
  tibble::rownames_to_column("refinebio_accession_code") %>%
  # Add the metadata into this data frame. Match by sample IDs
  dplyr::inner_join(metadata, by = "refinebio_accession_code")
#umap_plot_df (no need to show table, takes up 100 pages on pdf)
ggplot(
  umap_plot_df,
  aes(
    x = X1,
    y = X2,
    color = diabetes
  )
) +
  geom_point() # Plot individual points to make a scatterplot
```

-   [‚≠êÔ∏è UMAP Colored by Groups (3+ Students)]{.underline}

    Save your plot(s) and summarize your findings.

-   UMAP Plot Summary - [The UMAP plot shows that the two groups are
    clustered together in distinct groups. These clusters are the two
    different cell types, diabetic and reference. There are a few
    outliers in the plot where a few samples are displayed at the bottom
    of the plot.]{.underline}

-   PCA Plot vs UMAP Plot Comparison - [PCA is a linear technique that
    captures global structure and is computationally efficient, while
    UMAP is a nonlinear technique that excels at preserving local
    structure, making it well-suited for exploring complex relationships
    and identifying clusters in high-dimensional data.]{.underline}

```{r}
#Cleanup
rm(dds_norm)
rm(gene)
rm(gene_norm)
rm(new_expression_df)
rm(normalized_counts)
rm(pca_results)
rm(umap_plot_df)
rm(umap_results)
rm(ddset)
```

### 3. Perform differential analysis on the samples from your two groups, following the directions below

-   alexslemonade.github.io/refinebio-examples/03-rnaseq/differential-expression_rnaseq_01.html

-   Create a volcano plot of your data, following the directions above

    ```{r include=FALSE}
    if (!("EnhancedVolcano" %in% installed.packages())) {
      # Install this package if it isn't installed yet
      BiocManager::install("EnhancedVolcano", update = FALSE)
    }
    if (!("apeglm" %in% installed.packages())) {
      # Install this package if it isn't installed yet
      BiocManager::install("apeglm", update = FALSE)
    }

    # Attach the ggplot2 library for plotting
    library(ggplot2)

    # We will need this so we can use the pipe: %>%
    library(magrittr)
    ```

    Volcano plot time.

    ```{r include=FALSE}
    filtered_expression_df <- culled_expression_df %>%
      dplyr::filter(rowSums(.) >= 4000)

    #This culls roughly 35000 genes that show insignificant expression.

    gene_matrix <- round(filtered_expression_df)
    ddset <- DESeqDataSetFromMatrix(
      # Here we supply non-normalized count data
      countData = gene_matrix,
      # Supply the `colData` with our metadata data frame
      colData = culledMeta,
      # Supply our experimental variable to `design`
      design = ~diabetes
    )
    ```

    ```{r}
    #This WILL take some time. To reduce it down from a minute, use adjust the number on the third line of the above cell. The higher, the more genes filtered out, the shorter DESeq will take but the worse the volcano plot will be.
    deseq_object <- DESeq(ddset)
    ```

    ```{r include=FALSE}
    deseq_results <- results(deseq_object)
    deseq_results <- lfcShrink(
      deseq_object, # The original DESeq2 object after running DESeq()
      coef = 2, # The log fold change coefficient used in DESeq(); the default is 2.
      res = deseq_results # The original DESeq2 results table
    )

    # this is of class DESeqResults -- we want a data frame
    deseq_df <- deseq_results %>%
      # make into data.frame
      as.data.frame() %>%
      # the gene names are row names -- let's make them a column for easy display
      tibble::rownames_to_column("Gene") %>%
      # add a column for significance threshold results
      dplyr::mutate(threshold = padj < 0.05) %>%
      # sort by statistic
      dplyr::arrange(dplyr::desc(log2FoldChange))

    volcano_plot <- EnhancedVolcano::EnhancedVolcano(
      deseq_df,
      lab = deseq_df$Gene,
      x = "log2FoldChange",
      y = "padj",
      pCutoff = 0.01
    )

    ```

    \
    [‚≠êÔ∏èVolcano Plot Showing Log Fold Change and
    Significance]{.underline}

    ```{r}
    # Print out plot here
    volcano_plot
    ```

-   Create a table of differentially expressed genes.

    ‚≠êÔ∏èTable of statistically significant differentially expression genes
    including method-dependent relevant info (p-value, log fold change,
    etc).

    ```{r}
    head(deseq_df)
    ```

-   Save and summarize your findings.

    ```{r include=FALSE}
    readr::write_tsv(
      deseq_df,
      file.path(
        results_dir,
        "diff_expr_results.tsv" # Replace with a relevant output file name
      )
    )
    ```

[It seems a handful of genes have stood out as having significant fold
change in bot the positive and negative direction relative to the
control. Of the 6827 genes examined, 357 meet the threshold discovered
for significant change in differential expression, visualized as north
of the grey line towards the bottom of the volcano plot. Some are
exceptionally negative / positive, and are labeled for their
uniqueness.]{.underline}

```{r}
#Cleanup

```

### 4. Extract the list of significantly differentially expressed genes, and generate a heatmap using ComplexHeatmap

-   Package reference
    (<https://jokergoo.github.io/ComplexHeatmap-reference/book/>)

-   Add a side bar colored by sample groupings (cancer vs not, etc.)

```{r include=FALSE}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("ComplexHeatmap")
```

```{r}
#transpose expression_df so it can merge
#extract only the Gene column from data
transposed <- expression_df
transposed <- t(transposed)
transposed <- as.data.frame(transposed)
transposed <- transposed %>%
  tibble::rownames_to_column("Code")
transposed <- transposed[-1,]
```

```{r}
#rename ascession_code in copy of metadata to "Code" for merge to work, and cull unneeded columns
metadata_test <- metadata
names(metadata_test)[names(metadata_test) == "refinebio_accession_code"] <- "Code"
merge_filter = metadata_test[,c("Code","refinebio_subject")]

#merge culled metadata with transposed
merged <- merge(transposed,merge_filter,by="Code")
```

```{r include=FALSE}
#extract ONLY significantly expressed genes
deseq_df_enr <- readr::read_tsv(file.path(results_dir, "diff_expr_results.tsv"))
deseq_df_enr<-deseq_df_enr[(deseq_df_enr$threshold==TRUE),]

merged <- merged[,c("refinebio_subject", deseq_df_enr$Gene)]
```

```{r include=FALSE}
#group by refinebio subject
new_merged <- aggregate(merged, list(merged$refinebio_subject), FUN=mean)
new_merged <- new_merged[order(new_merged$Group.1),]
new_merged <- new_merged[-c(2)] %>% 
  column_to_rownames(var="Group.1")

row_names_df_to_remove<-c("pancreatic islets")
new_merged <- new_merged[!(row.names(new_merged) %in% row_names_df_to_remove),]
```

```{r}

#heatmap

ht = ComplexHeatmap::Heatmap(new_merged,heatmap_legend_param = list(
        title = "Expression", at = c(0, 50, 100,150)
    ),column_title = "Significantly Differentially Expressed Genes Heatmap",show_column_names = FALSE,cluster_columns = FALSE,cluster_rows = FALSE)
ComplexHeatmap::draw(ht)
```

‚≠êÔ∏è[Heatmap created using ComplexHeatmap showing the differentially
expressed genes. Side bar added that shows samples groups (cancer vs
not).]{.underline}

### HEATMAP SUMMARY:

[To create this Heatmap, we used ComplexHeatmap and simply aligned our
raw data with the significantly expressed gene table, then fed in only
the significantly expressed gene data to ComplexHeatmap. We also grouped
this data by the subject, with "non t2d" denoting a subject without Type
2 Diabetes and "t2d" denoting a subject with diabetes. We found that
ComplexHeatmap's default settings clustered the rows and columns so that
they appeared in a different order than how they appear in the input
table. To fix this, we set cluster to FALSE for both rows and
columns.]{.underline}

[Based on this heatmap from our significantly expressed gene data, there
does appear to be some degree of difference between how certain groups
of genes are expressed across the subjects with diabetes and those
without. Interestingly, there appear to be differences in how diabetes
is expressed within the diabetes groups, with subjects 1,2, and 3
differing from subjects 4,5, and 6. A similar division within the
non-diabetes group, if it exists, does not appear to be quite as
apparent.]{.underline}

### 5. Run enrichment analysis on your data using your selected method and ontology

Extract the list of deferentially expressed genes and run enrichment
analysis.

```{r include=FALSE}
#Extracting differentially expressed genes:
deseq_df_enr <- readr::read_tsv(file.path(results_dir, "diff_expr_results.tsv"))
deseq_df_enr<-deseq_df_enr[(deseq_df_enr$threshold==TRUE),]

readr::write_tsv(
  deseq_df_enr,
  file.path(
    results_dir,
    "diff_expr_results_enr.tsv" # Replace with a relevant output file name
  )
)
```

Each student in your team should run a different method OR ontology
(e.g., if there are 4 students on the team, there should be results for
4 applications in your assignment writeup).

-   Choose a method:

    -   gProfiler2

[We have opted to use gprofiler2 to avoid the challenges associated with
writing R and manipulating our already conclusive data. All three of us
are exploring three different ontologies: Biological pathways (<GO:BP>),
Molecular Function (<GO:MF>), and Cellular Components (<GO:CC>). The
above code isolates only statistically significant genes which we can
then paste into gprofiler/gost. Seeing as part 5 contains no further
instructions, see part 6 for corresponding write up.]{.underline}

### 6. Create a table of the enriched processes found for each method in step 4 (one table per method). Create a table showing statistically significantly enriched terms and any characteristics shared by the method you used (e.g., q-value, p-value, log fold change)

![](https://cdn.discordapp.com/attachments/1148297410318176256/1156772921298124830/gProfiler_hsapiens_2023-09-28_01-39-56.png)

‚≠êÔ∏è method/ontology pair per student, table for each method/ontology pair
with enriched terms (GO, msigDB, etc)

[(gost - Biological Pathways, gost - Molecular Function, gost - Cellular
Components)]{.underline}

[The above table was produced using gost, an online tool that attempts
to display genes clustered by various ontologies, ontologies being such
significance as the molecule to which they contribute, regulatory
effects they perform, or relationship with a disease among other
categories.]{.underline}

![](https://media.discordapp.net/attachments/1148297410318176256/1157136634630914088/image.png?ex=651782f8&is=65163178&hm=d2169b4059aa2d790085602ebe26e99871f8838137e09a8539b807cd954dce10)

[Of most signficance is cytoplasmic relationship within particularly the
<GO:CC> table. We can see a very significant P value here of
1.324x10\^-14, which is seemingly reasonable since diabetes would
influence certain metabolic pathways naturally present in the cytoplasm,
or so we would assume from the results. This lead to a further
exploration on google scholar, which lead to [this
paper.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8115730/),
suggesting that NADPH is depleted and lipogenesis from glucose dampened
as a consequence of T2D in pancreatic islet cells. We can also see that
functions relating to vesicles are affected, which falls in line with
the paper's suggestion that secretion is hampered (note the secretory
vesicle , around halfway down in terms of significance).]{.underline}

![](https://media.discordapp.net/attachments/1148297410318176256/1157136583170990101/image.png?ex=651782eb&is=6516316b&hm=8aeebd2dd26d4821c6261d2d69e83c867157e9603f4e7ba4992e0f773dc64210.png)

[Biological quality regulation was also closely tied to the differential
expression of our genes, under the biological pathway ontology. This too
is somewhat unsurprising, given this disease might be tied to
underperformant pancreatic islet cells. Particularly the relation to
"amide metabolic process" is more specific than the other points noted
in the table, and prompted some investigation. [This
paper](https://pubmed.ncbi.nlm.nih.gov/9421375/) seems to connect amides
(which we recognize are just a molecular component) to insulin
secretion, which confirms some of the findings from the cellular
component ontological exploration above.]{.underline}

![](https://media.discordapp.net/attachments/1148297410318176256/1157136538736529478/image.png?ex=651782e1&is=65163161&hm=a55dd1f1c74a8a45059a5707572a53639b89814596be219b20d76718aa27f9e5)

[Finally we see a connection to protein binding and phosphoric diester
hydrolase activity within the molecular function ontology. This is
intriguing as it may relate to insulin receptors' capacity to bind free
glucose, though it is our understanding that this is a fundamental
quality not only of pancreatic islet cells but of all somatic cells
participating in metabolism. Instead we explore phosphoric diester
hydrolase activity in an effort to supplement our understanding: It
turns out that phsophate diester hydrolases are closely tied to cAMP
regulation which we know from AP Biology regulates the cell cycle in
some capacity. When searching specifically for a connection to
pancreatic islets however, we find [the following
paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5587329/#:~:text=In%20addition%20to,conjugation%20with%20glutathione.)
which seems to suggest a connection to type 1 diabetes in which this
very class of enzyme's downregulation contributes to oxidative stress
and general disfunction.]{.underline}

### 7. Write a short summary to go with each plot/table you create. Describe what you did, what parameters you used (if any) and an interesting result from it.

‚≠êÔ∏èDone throughout.

‚≠êÔ∏è As a team, fill out the team evaluation table below.

![im1](https://cdn.discordapp.com/attachments/1148297410318176256/1156784591059816558/image.png)

### 8. Combine all into a single file and submit on Canvas. Make sure that all your code is added to your GitHub repository. ‚úÖ

[Github Link](https://github.com/Skunkmeister/CGS4144-Team12)
