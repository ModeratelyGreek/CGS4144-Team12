---
title: "Assignment 4 R Notebook"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
editor_options:
  markdown:
    wrap: 72
---

# Assignment 4 - Predictive Modeling

1.  [**Load into R the expression data and matching metadata that you
    processed in Assignment 2.**]{.underline}

Please insert your data files in the data directory such that the single
folder from refine.bio containing the metadata TSV and main TSV file are
present in the immediate subdirectory. This can be downloaded from
google drive,
[here!](https://drive.google.com/file/d/1aOnupOgIn-b7rSoGdRflNBvpfQPcR5v5/view?usp=sharing "Download folder to be unzipped as subdirectory of Data!")

This next step loads data and annotation libraries per the instructions,
but does not attempt to transform our Gene column to the Entrez IDs as
this was unnecessary for downstream processing.

```{r include=FALSE}
# Mount requisite libraries, install clustering lib
library(dplyr)
library(tidyverse)
library(readr)
library(factoextra)
library(caret)
library(mlr3)
library(mlr3learners)
library(mlr3tuning)

library(data.table)
remotes::install_github("mlr-org/mlr3extralearners@*release")
library(mlr3verse)
library(mlr3tuning)
library(data.table)
library(ggplot2)
library(ggalluvial)
library(magrittr)
library(mlr3extralearners)
library(pheatmap)
library(ranger)

# Create the data folder if it doesn't exist
if (!dir.exists("data")) {
  dir.create("data")
}
# Define the file path to the plots directory
plots_dir <- "plots"
# Create the plots folder if it doesn't exist
if (!dir.exists(plots_dir)) {
  dir.create(plots_dir)
}
# Define the file path to the results directory
results_dir <- "results"
# Create the results folder if it doesn't exist
if (!dir.exists(results_dir)) {
  dir.create(results_dir)
}
# Define the file path to the data directory
data_dir <- file.path("data", "SRP075377")
# Declare the file path to the gene expression matrix file inside directory saved as `data_dir`
data_file <- file.path(data_dir, "SRP075377.tsv")
# Declare the file path to the metadata file inside the directory saved as `data_dir`
metadata_file <- file.path(data_dir, "metadata_SRP075377.tsv")
# Attach library for pipe (%>%)
```

```{r}
# Check that files exist and are usable.
file.exists(data_file)
file.exists(metadata_file)
```

```{r include=FALSE}
# Read in data and metadata TSV file and make Gene column into row names
metadata <- readr::read_tsv(metadata_file)
new_expression_df <- readr::read_tsv(data_file) %>%
  tibble::column_to_rownames("Gene")

metadata <- metadata %>%
  dplyr::mutate(diabetes = dplyr::case_when(
    stringr::str_detect(refinebio_subject, "non t2d") ~ "reference",
    stringr::str_detect(refinebio_subject, "t2d") ~ "diabetic",
  ))

#Remove ambiguously-labeled samples from metadata
culledMeta <- metadata[!(metadata$refinebio_subject=="pancreatic islets"),]

discardColumns <- metadata[(metadata$refinebio_subject=="pancreatic islets"),]
discardColumns = as.vector(discardColumns$refinebio_accession_code)
length(discardColumns)
#Preserve only columns in expression_df that match one of the accession ids
culled_expression_df = new_expression_df[,!(names(new_expression_df) %in% discardColumns)]

#expression_df <- as.data.frame(t(culled_expression_df))
expression_df <- culled_expression_df
```

```{r}
#
referenceGroup <- subset(culledMeta, select = c("refinebio_accession_code", "diabetes"))
referenceGroup <- referenceGroup %>%
  dplyr::mutate(diabetes = dplyr::case_when(
    stringr::str_detect(diabetes, "reference") ~ 0,
    stringr::str_detect(diabetes, "diabetic") ~ 1,
  ))

reference_group <- referenceGroup$diabetes
```

2. Supervised Analysis
  a. Subset your data to the 5,000 most variable genes
  b. Using that subset of the data, select and run an algorithm from this list:
    i. Support vector machine
    ii. Logistic regression
    iii. Random forest
    iv. K nearest neighbors
    v. Naïve Bayes
  c. I recommend using either TidyModels or the mlr3 package. Tutorials:
    i. https://mlr3.mlr-org.com/
    ii. https://seandavi.github.io/ITR/machine_learning_mlr3.html
    iii. https://www.tidymodels.org/start/
  d. Have the algorithms predict the two groups from assignment 1 (e.g. tumor vs normal)
  e. Each student in your team should run a different supervised analysis method (e.g., if      there are 4 students on the team, there should be results for 4 predictive methods in      your assignment writeup).
  f. Extract the gene signatures from the model.
    i. How many genes are in each of the predictive method signatures?
    ii. How much overlap is there between the signatures?
  g. Rerun each predictive method using different numbers of genes. Try 10, 100, 1000, and      10000 genes.
    i. How did the number of genes affect the results?
    ii. Are the same genes being included in the models? How much overlap is there between         the signatures?
    iii. What is the model performance (AUC) for each of the different versions of the              model? Does it increase or decrease as the number of genes included in the model           changes?

# 2A: Subset your data to the 5,000 most variable genes

```{r include=FALSE}
# Calculate row variance
row_variances <- apply(expression_df, 1, mad)
expression_df$row_variance <- row_variances
# Sort by row variance
expression_df <- expression_df[order(row_variances, decreasing = TRUE), ]

# Remove the row variance column
expression_df <- select(expression_df, -row_variance)

top_5000 <- head(expression_df, 5000)
top_5000 <- as.data.frame(t(top_5000))

top_10 <- head(expression_df, 10)
top_100 <- head(expression_df, 100)
top_1000 <- head(expression_df, 1000)
top_10000 <- head(expression_df, 10000)
top_10 <- as.data.frame(t(top_10))
top_100 <- as.data.frame(t(top_100))
top_1000 <- as.data.frame(t(top_1000))
top_10000 <- as.data.frame(t(top_10000))
```

# 2B: Using that subset of the data, select and run an algorithm from this list:
    i. Support vector machine
    ii. Logistic regression
    iii. Random forest
    iv. K nearest neighbors
    v. Naïve Bayes
    
# LOGISTIC REGRESSION MODEL 
```{r}
#TEN GENES
#data wranglign from michael 
top_10$refinebio_accession_code <- rownames(top_10) 
top_10_labeled <- merge(top_10, referenceGroup, by = "refinebio_accession_code")
top_10 <- select(top_10, -refinebio_accession_code)
rownames(top_10_labeled) <- top_10_labeled$refinebio_accession_code
top_10_labeled <- select(top_10_labeled, -refinebio_accession_code)
top_10_labeled$diabetes <- factor(top_10_labeled$diabetes, levels = c(0, 1), labels = c("Non-Diabetic", "Diabetic"))

#create classification task
task <- TaskClassif$new(
  "gene_exp",
  top_10_labeled,
  "diabetes",
  positive = "Diabetic",
  label = NA_character_,
  extra_args = list()
)
#task

#split the data, train model
set.seed(123)
split = partition(task, ratio = 0.7)
learner <- lrn("classif.log_reg",predict_type = "prob")
learner$train(task, split$train) #train model
#learner$model # view trained model

pred_train = learner$predict(task, row_ids=split$train)
pred_test <- learner$predict(task, row_ids=split$test)
#pred_train$confusion #confusion matrix of data on train set, useless obv but just wanna see
conf_matrix <- pred_test$confusion #confusion matrix of data on test set
#results from above kindof demonstrate that the model, even on the train set, often misidentifies non-diabetic as diabetic, it is very good as determining the actually diabetic ones though
conf_matrix


#signature genes as per michael
N <- 2
signature_genes_LR_10 <- names(sort(learner$model$coefficients, decreasing = T))[1:N]



#CALCULATE CONFUSION MATRIX STUFF HERE
#since our confusion matrix is flipped and True Positive is based on correct detection of "Non-Diabetic" rather than "Diabetic", we can compute the correct scores by 
#calculating True Negative Rate and False Negative Rate for TPR (Recall) and FPR
print(pred_test$score(msr(c("classif.tpr"))))
print(pred_test$score(msr(c("classif.fpr"))))
aucMsr <- msr("classif.auc")
AUC = aucMsr$score(prediction = pred_test)


cat("AUC:", AUC,"\n")

```


```{r}
#ONE HUNDRED LOG REG
#data wranglign from michael 
top_100$refinebio_accession_code <- rownames(top_100) 
top_100_labeled <- merge(top_100, referenceGroup, by = "refinebio_accession_code")
top_100 <- select(top_100, -refinebio_accession_code)
rownames(top_100_labeled) <- top_100_labeled$refinebio_accession_code
top_100_labeled <- select(top_100_labeled, -refinebio_accession_code)
top_100_labeled$diabetes <- factor(top_100_labeled$diabetes, levels = c(0, 1), labels = c("Non-Diabetic", "Diabetic"))

#create classification task
task <- TaskClassif$new(
  "gene_exp",
  top_100_labeled,
  "diabetes",
  positive = NULL,
  label = NA_character_,
  extra_args = list()
)
#task

#split the data, train model
set.seed(123)
split = partition(task, ratio = 0.7)
learner <- lrn("classif.log_reg",predict_type = "prob")
learner$train(task, split$train) #train model
#earner$model$coefficients 

#pred_train = learner$predict(task, row_ids=split$train)
pred_test <- learner$predict(task, row_ids=split$test)
conf_matrix <- pred_test$confusion 
conf_matrix

#signature genes as per michael
N <- 4
signature_genes_LR_100 <- names(sort(learner$model$coefficients, decreasing = T))[1:N]



print(pred_test$score(msr(c("classif.tpr"))))
print(pred_test$score(msr(c("classif.fpr"))))
AUC = aucMsr$score(prediction = pred_test)

cat("AUC:", AUC,"\n")

```


```{r}
stuff <- learner$model$coefficients
#ONE THOUSAND LOG REG
#data wranglign from michael 
top_1000$refinebio_accession_code <- rownames(top_1000) 
top_1000_labeled <- merge(top_1000, referenceGroup, by = "refinebio_accession_code")
top_1000 <- select(top_1000, -refinebio_accession_code)
rownames(top_1000_labeled) <- top_1000_labeled$refinebio_accession_code
top_1000_labeled <- select(top_1000_labeled, -refinebio_accession_code)
top_1000_labeled$diabetes <- factor(top_1000_labeled$diabetes, levels = c(0, 1), labels = c("Non-Diabetic", "Diabetic"))

#create classification task
task <- TaskClassif$new(
  "gene_exp",
  top_1000_labeled,
  "diabetes",
  positive = NULL,
  label = NA_character_,
  extra_args = list()
)
#task

#split the data, train model
set.seed(123)
split = partition(task, ratio = 0.7)
learner <- lrn("classif.log_reg",predict_type = "prob")
learner$train(task, split$train) #train model
#learner$model # view trained model

#pred_train = learner$predict(task, row_ids=split$train)
pred_test <- learner$predict(task, row_ids=split$test)
conf_matrix <- pred_test$confusion 
conf_matrix

# Get genes in top weight percentile by percent below:

#signature genes as per michael
N <- 10
signature_genes_LR_1000<- names(sort(learner$model$coefficients, decreasing = T))[1:N]



print(pred_test$score(msr(c("classif.tpr"))))
print(pred_test$score(msr(c("classif.fpr"))))
AUC = aucMsr$score(prediction = pred_test)

cat("AUC:", AUC,"\n")

```

```{r}
#FIVE THOUSAND LOG REG
#data wranglign from michael 
top_5000$refinebio_accession_code <- rownames(top_5000) 
top_5000_labeled <- merge(top_5000, referenceGroup, by = "refinebio_accession_code")
top_5000 <- select(top_5000, -refinebio_accession_code)
rownames(top_5000_labeled) <- top_5000_labeled$refinebio_accession_code
top_5000_labeled <- select(top_5000_labeled, -refinebio_accession_code)
top_5000_labeled$diabetes <- factor(top_5000_labeled$diabetes, levels = c(0, 1), labels = c("Non-Diabetic", "Diabetic"))

#create classification task
task <- TaskClassif$new(
  "gene_exp",
  top_5000_labeled,
  "diabetes",
  positive = NULL,
  label = NA_character_,
  extra_args = list()
)
#task

#split the data, train model
set.seed(123)
split = partition(task, ratio = 0.7)
learner <- lrn("classif.log_reg",predict_type = "prob")
learner$train(task, split$train) #train model
#learner$model # view trained model

#pred_train = learner$predict(task, row_ids=split$train)
pred_test <- learner$predict(task, row_ids=split$test)
conf_matrix <- pred_test$confusion 
conf_matrix

#signature genes as per michael
N <- 17
signature_genes_LR_5000 <- names(sort(learner$model$coefficients, decreasing = T))[1:N]


print(pred_test$score(msr(c("classif.tpr"))))
print(pred_test$score(msr(c("classif.fpr"))))
AUC = aucMsr$score(prediction = pred_test)


cat("AUC:", AUC,"\n")

```

```{r}
#TEN THOUSAND LOG REG
#data wranglign from michael 
top_10000$refinebio_accession_code <- rownames(top_10000) 
top_10000_labeled <- merge(top_10000, referenceGroup, by = "refinebio_accession_code")
top_10000 <- select(top_10000, -refinebio_accession_code)
rownames(top_10000_labeled) <- top_10000_labeled$refinebio_accession_code
top_10000_labeled <- select(top_10000_labeled, -refinebio_accession_code)
top_10000_labeled$diabetes <- factor(top_10000_labeled$diabetes, levels = c(0, 1), labels = c("Non-Diabetic", "Diabetic"))

#create classification task
task <- TaskClassif$new(
  "gene_exp",
  top_10000_labeled,
  "diabetes",
  positive = NULL,
  label = NA_character_,
  extra_args = list()
)
#task

#split the data, train model
set.seed(123)
split = partition(task, ratio = 0.7)
learner <- lrn("classif.log_reg",predict_type = "prob")
learner$train(task, split$train) #train model
#learner$model # view trained model

#pred_train = learner$predict(task, row_ids=split$train)
pred_test <- learner$predict(task, row_ids=split$test)
conf_matrix <- pred_test$confusion 
conf_matrix

#signature genes as per michael
N <- 21
signature_genes_LR_10000 <- names(sort(learner$model$coefficients, decreasing = T))[1:N]



print(pred_test$score(msr(c("classif.tpr"))))
print(pred_test$score(msr(c("classif.fpr"))))
AUC = aucMsr$score(prediction = pred_test)


```
    
#OVERLAP FOR LOGISTIC REGRESSION
```{r}
vectors <- list(
  LR10=signature_genes_LR_10,
  LR100=signature_genes_LR_100,
  LR1000=signature_genes_LR_1000,
  LR5000=signature_genes_LR_5000,
  LR10000=signature_genes_LR_10000
)
  
# Initialize a matrix to store the fractions
overlap_matrix <- matrix(0, nrow = length(vectors), ncol = length(vectors))
# Calculate the fractions
for (i in 1:length(vectors)) {
  cat(names(vectors)[i], " signature gene #: ", length(vectors[[i]]), "\n")
  for (j in 1:length(vectors)) {
    if (i<j) {
      overlap_matrix[i,j]<-length(intersect(vectors[[i]], vectors[[j]])) / length(vectors[[i]])
    }
  }
}
cat("\n")
# Display the overlap matrix
rownames(overlap_matrix) <- colnames(overlap_matrix) <- c(
  "LR10",
  "LR100",
  "LR1000",
  "LR5000",
  "LR10000")
print(overlap_matrix)
```

    
# Random Forest Supervised Learning Algorithm

# Random Forest Algorithm Top 10 Most Variable Genes
```{r}
# set.seed(123)
# split = partition(Task_SVM_10000, ratio = 0.7)
# learner <- lrn("classif.svm", kernel = "linear", predict_type="prob")
# svm_model <- learner$train(Task_SVM_10000, split$train)
# predictions <- learner$predict(Task_SVM_10000, split$test)
# model <- svm_model$model
# 
# # Get genes in top weight percentile by percent below:
# gene_weights <- t(model$SV) %*% model$coefs
# N <- 22 
# ordered_indices <- order(abs(as.numeric(gene_weights)), decreasing = TRUE)[1:N]
# signature_genes_SVM_10000 <- colnames(top_10000)[ordered_indices]


temp <- as.data.frame(t(expression_df))
temp$refinebio_accession_code <- rownames(temp)
expression_df_labeled <- merge(temp, referenceGroup, by = "refinebio_accession_code")
rm(temp)
rownames(expression_df_labeled) <- expression_df_labeled$refinebio_accession_code
expression_df_labeled <- select(expression_df_labeled, -refinebio_accession_code)
expression_df_labeled$diabetes <- factor(
  expression_df_labeled$diabetes,
  levels = c(0, 1), labels = c("Non-Diabetic", "Diabetic")
)

top_10 <- select(expression_df_labeled, 1:10, ncol(expression_df_labeled))

#create classification task
task <- TaskClassif$new(
  "gene_exp",
  top_10,
  "diabetes",
  positive = "Diabetic",
  label = NA_character_,
  extra_args = list()
)
set.seed(123)
# Split the data into training and testing sets
split <- partition(task, ratio = 0.7)
learner <- lrn("classif.ranger",predict_type = "prob")
learner$train(task, split$train) #train model

pred_train = learner$predict(task, row_ids=split$train)
pred_test <- learner$predict(task, row_ids=split$test)

conf_matrix <- pred_test$confusion

conf_matrix

#signature genes
N <- 2
signature_genes_RF_10 <- names(sort(learner$model$coefficients, decreasing = T))[1:N]
# ranger_model <- learner$model
# feature_importances <- ranger_model$variable.importance
# sorted_importances <- sort(feature_importances, decreasing = TRUE)
# signature_genes_RF_10 <- names(sorted_importances[1:N])

print(pred_test$score(msr(c("classif.tpr"))))
print(pred_test$score(msr(c("classif.fpr"))))
aucMsr <- msr("classif.auc")
AUC = aucMsr$score(prediction = pred_test)
cat("AUC:", AUC,"\n")
```

# Random Forest Algorithm Top 100 Most Variable Genes
```{r}
temp <- as.data.frame(t(expression_df))
temp$refinebio_accession_code <- rownames(temp)
expression_df_labeled <- merge(temp, referenceGroup, by = "refinebio_accession_code")
rm(temp)
rownames(expression_df_labeled) <- expression_df_labeled$refinebio_accession_code
expression_df_labeled <- select(expression_df_labeled, -refinebio_accession_code)
expression_df_labeled$diabetes <- factor(
  expression_df_labeled$diabetes,
  levels = c(0, 1), labels = c("Non-Diabetic", "Diabetic")
)

top_100 <- select(expression_df_labeled, 1:100, ncol(expression_df_labeled))

#create classification task
task <- TaskClassif$new(
  "gene_exp",
  top_100,
  "diabetes",
  positive = "Diabetic",
  label = NA_character_,
  extra_args = list()
)
set.seed(123)
# Split the data into training and testing sets
split <- partition(task, ratio = 0.7)
learner <- lrn("classif.ranger",predict_type = "prob")
learner$train(task, split$train) #train model

pred_train = learner$predict(task, row_ids=split$train)
pred_test <- learner$predict(task, row_ids=split$test)

conf_matrix <- pred_test$confusion

conf_matrix

#signature genes
N <- 5
signature_genes_RF_100 <- names(sort(learner$model$coefficients, decreasing = T))[1:N]

print(pred_test$score(msr(c("classif.tpr"))))
print(pred_test$score(msr(c("classif.fpr"))))
aucMsr <- msr("classif.auc")
AUC = aucMsr$score(prediction = pred_test)
cat("AUC:", AUC,"\n")
```

# Random Forest Algorithm Top 1000 Most Variable Genes
```{r}
temp <- as.data.frame(t(expression_df))
temp$refinebio_accession_code <- rownames(temp)
expression_df_labeled <- merge(temp, referenceGroup, by = "refinebio_accession_code")
rm(temp)
rownames(expression_df_labeled) <- expression_df_labeled$refinebio_accession_code
expression_df_labeled <- select(expression_df_labeled, -refinebio_accession_code)
expression_df_labeled$diabetes <- factor(
  expression_df_labeled$diabetes,
  levels = c(0, 1), labels = c("Non-Diabetic", "Diabetic")
)

top_1000 <- select(expression_df_labeled, 1:1000, ncol(expression_df_labeled))

#create classification task
task <- TaskClassif$new(
  "gene_exp",
  top_1000,
  "diabetes",
  positive = "Diabetic",
  label = NA_character_,
  extra_args = list()
)
set.seed(123)
# Split the data into training and testing sets
split <- partition(task, ratio = 0.7)
learner <- lrn("classif.ranger",predict_type = "prob")
learner$train(task, split$train) #train model

pred_train = learner$predict(task, row_ids=split$train)
pred_test <- learner$predict(task, row_ids=split$test)

conf_matrix <- pred_test$confusion

conf_matrix

#signature genes
N <- 10
signature_genes_RF_1000 <- names(sort(learner$model$coefficients, decreasing = T))[1:N]

print(pred_test$score(msr(c("classif.tpr"))))
print(pred_test$score(msr(c("classif.fpr"))))
aucMsr <- msr("classif.auc")
AUC = aucMsr$score(prediction = pred_test)
cat("AUC:", AUC,"\n")
```

# Random Forest Algorithm Top 5000 Most Variable Genes
```{r}
temp <- as.data.frame(t(expression_df))
temp$refinebio_accession_code <- rownames(temp)
expression_df_labeled <- merge(temp, referenceGroup, by = "refinebio_accession_code")
rm(temp)
rownames(expression_df_labeled) <- expression_df_labeled$refinebio_accession_code
expression_df_labeled <- select(expression_df_labeled, -refinebio_accession_code)
expression_df_labeled$diabetes <- factor(
  expression_df_labeled$diabetes,
  levels = c(0, 1), labels = c("Non-Diabetic", "Diabetic")
)

top_5000 <- select(expression_df_labeled, 1:5000, ncol(expression_df_labeled))

#create classification task
task <- TaskClassif$new(
  "gene_exp",
  top_5000,
  "diabetes",
  positive = "Diabetic",
  label = NA_character_,
  extra_args = list()
)
set.seed(123)
# Split the data into training and testing sets
split <- partition(task, ratio = 0.7)
learner <- lrn("classif.ranger",predict_type = "prob")
learner$train(task, split$train) #train model

pred_train = learner$predict(task, row_ids=split$train)
pred_test <- learner$predict(task, row_ids=split$test)

conf_matrix <- pred_test$confusion

conf_matrix

#signature genes
N <- 17
signature_genes_RF_5000 <- names(sort(learner$model$coefficients, decreasing = T))[1:N]

print(pred_test$score(msr(c("classif.tpr"))))
print(pred_test$score(msr(c("classif.fpr"))))
aucMsr <- msr("classif.auc")
AUC = aucMsr$score(prediction = pred_test)
cat("AUC:", AUC,"\n")
```

# Random Forest Algorithm Top 10000 Most Variable Genes
```{r}
temp <- as.data.frame(t(expression_df))
temp$refinebio_accession_code <- rownames(temp)
expression_df_labeled <- merge(temp, referenceGroup, by = "refinebio_accession_code")
rm(temp)
rownames(expression_df_labeled) <- expression_df_labeled$refinebio_accession_code
expression_df_labeled <- select(expression_df_labeled, -refinebio_accession_code)
expression_df_labeled$diabetes <- factor(
  expression_df_labeled$diabetes,
  levels = c(0, 1), labels = c("Non-Diabetic", "Diabetic")
)

top_10000 <- select(expression_df_labeled, 1:10000, ncol(expression_df_labeled))

#create classification task
task <- TaskClassif$new(
  "gene_exp",
  top_10000,
  "diabetes",
  positive = "Diabetic",
  label = NA_character_,
  extra_args = list()
)
set.seed(123)
# Split the data into training and testing sets
split <- partition(task, ratio = 0.7)
learner <- lrn("classif.ranger",predict_type = "prob")
learner$train(task, split$train) #train model

pred_train = learner$predict(task, row_ids=split$train)
pred_test <- learner$predict(task, row_ids=split$test)

conf_matrix <- pred_test$confusion

conf_matrix

#signature genes
N <- 22
signature_genes_RF_10000 <- names(sort(learner$model$coefficients, decreasing = T))[1:N]

print(pred_test$score(msr(c("classif.tpr"))))
print(pred_test$score(msr(c("classif.fpr"))))
aucMsr <- msr("classif.auc")
AUC = aucMsr$score(prediction = pred_test)
cat("AUC:", AUC,"\n")
```

#Random Forest Gene Overlap
```{r}
vectors <- list(
  RF10=signature_genes_RF_10,
  RF100=signature_genes_RF_100,
  RF1000=signature_genes_RF_1000,
  RF5000=signature_genes_RF_5000,
  RF10000=signature_genes_RF_10000
)
  
# Initialize a matrix to store the fractions
overlap_matrix <- matrix(0, nrow = length(vectors), ncol = length(vectors))

# Calculate the fractions
for (i in 1:length(vectors)) {
  cat(names(vectors)[i], " signature gene #: ", length(vectors[[i]]), "\n")
  for (j in 1:length(vectors)) {
    if (i<j) {
      overlap_matrix[i,j]<-length(intersect(vectors[[i]], vectors[[j]])) / length(vectors[[i]])
    }
  }
}

cat("\n")

# Display the overlap matrix
rownames(overlap_matrix) <- colnames(overlap_matrix) <- c(
  "RF10",
  "RF100",
  "RF1000",
  "RF5000",
  "RF10000")
print(overlap_matrix)
```

```{r}
# Read in data and metadata TSV file and make Gene column into row names
metadata <- readr::read_tsv(metadata_file)
new_expression_df <- readr::read_tsv(data_file) %>%
  tibble::column_to_rownames("Gene")

metadata <- metadata %>%
  dplyr::mutate(diabetes = dplyr::case_when(
    stringr::str_detect(refinebio_subject, "non t2d") ~ "reference",
    stringr::str_detect(refinebio_subject, "t2d") ~ "diabetic",
  ))

#Remove ambiguously-labeled samples from metadata
culledMeta <- metadata[!(metadata$refinebio_subject=="pancreatic islets"),]

discardColumns <- metadata[(metadata$refinebio_subject=="pancreatic islets"),]
discardColumns = as.vector(discardColumns$refinebio_accession_code)
length(discardColumns)

#Preserve only columns in expression_df that match one of the accession ids
culled_expression_df = new_expression_df[,!(names(new_expression_df) %in% discardColumns)]

expression_df <- culled_expression_df
rm(metadata)
rm(new_expression_df)
rm(culled_expression_df)

referenceGroup <- subset(culledMeta, select = c("refinebio_accession_code", "diabetes"))
referenceGroup <- referenceGroup %>%
  dplyr::mutate(diabetes = dplyr::case_when(
    stringr::str_detect(diabetes, "reference") ~ 0,
    stringr::str_detect(diabetes, "diabetic") ~ 1,
  ))

reference_group <- referenceGroup$diabetes

# Calculate row variance
row_variances <- apply(expression_df, 1, mad)
expression_df$row_variance <- row_variances

# Sort by row variance
expression_df <- expression_df[order(row_variances, decreasing = TRUE), ]

# Remove the row variance column
expression_df <- select(expression_df, -row_variance)

#Rip out those pesky rownames, join on that column, then drop the column
temp <- as.data.frame(t(expression_df))
temp$refinebio_accession_code <- rownames(temp) 
expression_df_labeled <- merge(temp, referenceGroup, by = "refinebio_accession_code")
rm(temp)        
rownames(expression_df_labeled) <- expression_df_labeled$refinebio_accession_code
expression_df_labeled <- select(expression_df_labeled, -refinebio_accession_code)
expression_df_labeled$diabetes <- factor(
  expression_df_labeled$diabetes, 
  levels = c(0, 1), labels = c("Non-Diabetic", "Diabetic")
)

top_10 <- select(expression_df_labeled, 1:10, ncol(expression_df_labeled))
top_100 <- select(expression_df_labeled, 1:100, ncol(expression_df_labeled))
top_1000 <- select(expression_df_labeled, 1:1000, ncol(expression_df_labeled))
top_5000 <- select(expression_df_labeled, 1:5000, ncol(expression_df_labeled))
top_10000 <- select(expression_df_labeled, 1:10000, ncol(expression_df_labeled))
Task_SVM_10 <- TaskClassif$new(id = "gene_exp", backend = top_10, target = "diabetes")
Task_SVM_100 <- TaskClassif$new(id = "gene_exp", backend = top_100, target = "diabetes")
Task_SVM_1000 <- TaskClassif$new(id = "gene_exp", backend = top_1000, target = "diabetes")
Task_SVM_5000 <- TaskClassif$new(id = "gene_exp", backend = top_5000, target = "diabetes")
Task_SVM_10000 <- TaskClassif$new(id = "gene_exp", backend = top_10000, target = "diabetes")
```

# Support Vector Machines

## 🔀🔄⬇️ SVM - 10

```{r}
set.seed(123)
split = partition(Task_SVM_10, ratio = 0.7)
learner <- lrn("classif.svm", kernel = "linear", predict_type="prob")
svm_model <- learner$train(Task_SVM_10, split$train)
predictions <- learner$predict(Task_SVM_10, split$test)
model <- svm_model$model

# Get genes in top weight percentile by percent below:
gene_weights <- t(model$SV) %*% model$coefs
N <- 2 #sqrt(5000), arbitrarily
ordered_indices <- order(abs(as.numeric(gene_weights)), decreasing = TRUE)[1:N]
signature_genes_SVM_10 <- colnames(top_10)[ordered_indices]

# Get some metrics
cm = predictions$confusion
aucMsr <- msr("classif.auc")
AUC = aucMsr$score(prediction = predictions)
TPR = cm[2,2] / (cm[2,2] + cm[1,2])  # Sensitivity or Recall: TP / (TP + FN)
FPR = cm[2,1] / (cm[2,1] + cm[1,1])  # False Positive Rate: FP / (FP + TN)

# Spit it all out
print(cm)
cat("\n")
cat("Area Under Curve:", AUC, "\n")
cat("True Positive Rate:", TPR, "\n")
cat("False Positive Rate:", FPR, "\n")
```

## 🔀🔄⬇️ SVM - 100

```{r}
set.seed(123)
split = partition(Task_SVM_100, ratio = 0.7)
learner <- lrn("classif.svm", kernel = "linear", predict_type="prob")
svm_model <- learner$train(Task_SVM_100, split$train)
predictions <- learner$predict(Task_SVM_100, split$test)
model <- svm_model$model

# Get genes in top weight percentile by percent below:
gene_weights <- t(model$SV) %*% model$coefs
N <- 5 #sqrt(100), arbitrarily
ordered_indices <- order(abs(as.numeric(gene_weights)), decreasing = TRUE)[1:N]
signature_genes_SVM_100 <- colnames(top_100)[ordered_indices]

# Get some metrics
cm = predictions$confusion
aucMsr <- msr("classif.auc")
AUC = aucMsr$score(prediction = predictions)
TPR = cm[2,2] / (cm[2,2] + cm[1,2])  # Sensitivity or Recall: TP / (TP + FN)
FPR = cm[2,1] / (cm[2,1] + cm[1,1])  # False Positive Rate: FP / (FP + TN)

# Spit it all out
print(cm)
cat("\n")
cat("Area Under Curve:", AUC, "\n")
cat("True Positive Rate:", TPR, "\n")
cat("False Positive Rate:", FPR, "\n")
```

## 🔀🔄⬇️ SVM - 1,000

```{r}
set.seed(123)
split = partition(Task_SVM_1000, ratio = 0.7)
learner <- lrn("classif.svm", kernel = "linear", predict_type="prob")
svm_model <- learner$train(Task_SVM_1000, split$train)
predictions <- learner$predict(Task_SVM_1000, split$test)
model <- svm_model$model

# Get genes in top weight percentile by percent below:
gene_weights <- t(model$SV) %*% model$coefs
N <- 10 #sqrt(1000), arbitrarily
ordered_indices <- order(abs(as.numeric(gene_weights)), decreasing = TRUE)[1:N]
signature_genes_SVM_1000 <- colnames(top_1000)[ordered_indices]

# Get some metrics
cm = predictions$confusion
aucMsr <- msr("classif.auc")
AUC = aucMsr$score(prediction = predictions)
TPR = cm[2,2] / (cm[2,2] + cm[1,2])  # Sensitivity or Recall: TP / (TP + FN)
FPR = cm[2,1] / (cm[2,1] + cm[1,1])  # False Positive Rate: FP / (FP + TN)

# Spit it all out
print(cm)
cat("\n")
cat("Area Under Curve:", AUC, "\n")
cat("True Positive Rate:", TPR, "\n")
cat("False Positive Rate:", FPR, "\n")
```

## 🔀🔄⬇️ SVM - 5,000

```{r}
set.seed(123)
split = partition(Task_SVM_5000, ratio = 0.7)
learner <- lrn("classif.svm", kernel = "linear", predict_type="prob")
svm_model <- learner$train(Task_SVM_5000, split$train)
predictions <- learner$predict(Task_SVM_5000, split$test)
model <- svm_model$model

# Get genes in top weight percentile by percent below:
gene_weights <- t(model$SV) %*% model$coefs
N <- 17 # cbrt(5000), arbitrarily
ordered_indices <- order(abs(as.numeric(gene_weights)), decreasing = TRUE)[1:N]
signature_genes_SVM_5000 <- colnames(top_5000)[ordered_indices]

# Get some metrics
cm = predictions$confusion
aucMsr <- msr("classif.auc")
AUC = aucMsr$score(prediction = predictions)
TPR = cm[2,2] / (cm[2,2] + cm[1,2])  # Sensitivity or Recall: TP / (TP + FN)
FPR = cm[2,1] / (cm[2,1] + cm[1,1])  # False Positive Rate: FP / (FP + TN)

# Spit it all out
print(cm)
cat("\n")
cat("Area Under Curve:", AUC, "\n")
cat("True Positive Rate:", TPR, "\n")
cat("False Positive Rate:", FPR, "\n")
```

## 🔀🔄⬇️ SVM - 10,000

```{r}
set.seed(123)
split = partition(Task_SVM_10000, ratio = 0.7)
learner <- lrn("classif.svm", kernel = "linear", predict_type="prob")
svm_model <- learner$train(Task_SVM_10000, split$train)
predictions <- learner$predict(Task_SVM_10000, split$test)
model <- svm_model$model

# Get genes in top weight percentile by percent below:
gene_weights <- t(model$SV) %*% model$coefs
N <- 22 
ordered_indices <- order(abs(as.numeric(gene_weights)), decreasing = TRUE)[1:N]
signature_genes_SVM_10000 <- colnames(top_10000)[ordered_indices]

# Get some metrics
cm = predictions$confusion
aucMsr <- msr("classif.auc")
AUC = aucMsr$score(prediction = predictions)
TPR = cm[2,2] / (cm[2,2] + cm[1,2])  # Sensitivity or Recall: TP / (TP + FN)
FPR = cm[2,1] / (cm[2,1] + cm[1,1])  # False Positive Rate: FP / (FP + TN)

# Spit it all out
print(cm)
cat("\n")
cat("Area Under Curve:", AUC, "\n")
cat("True Positive Rate:", TPR, "\n")
cat("False Positive Rate:", FPR, "\n")
```

Model performance degrades at 10,000 genes. In order to attempt to
correct this I explored various kernels and hyperparameters including
RBF, Polynomial, and Sigmoid. None of these improved performance
although polynomial with a high coefficient got better results than the
others. What we're witnessing here is the "curse of dimensionality" to
SVM. It is overfitting to the noise produced by extending the feature
vector to include less relevant genes. I also attempted to improve
results, particularly the 0 TN FP rate (divide by zero error in AUC
calculation) by setting the classifier's class weights to the inverse of
their frequency as was recommended in several websites. Unfortunately
this did not improve the outcome, and SVM remains victim to overfitting
high-dimensional noise.

```{r}

vectors <- list(
  SVM10=signature_genes_SVM_10,
  SVM100=signature_genes_SVM_100,
  SVM1000=signature_genes_SVM_1000,
  SVM5000=signature_genes_SVM_5000,
  SVM10000=signature_genes_SVM_10000
)
  
# Initialize a matrix to store the fractions
overlap_matrix <- matrix(0, nrow = length(vectors), ncol = length(vectors))

# Calculate the fractions
for (i in 1:length(vectors)) {
  cat(names(vectors)[i], " signature gene #: ", length(vectors[[i]]), "\n")
  for (j in 1:length(vectors)) {
    if (i<j) {
      overlap_matrix[i,j]<-length(intersect(vectors[[i]], vectors[[j]])) / length(vectors[[i]])
    }
  }
}

cat("\n")

# Display the overlap matrix
rownames(overlap_matrix) <- colnames(overlap_matrix) <- c(
  "SVM10",
  "SVM100",
  "SVM1000",
  "SVM5000",
  "SVM10000")
print(overlap_matrix)
```

No overlap, wild.

# Heatmap 🌶️🗺️

Gather superset of all unique genes.

```{r}
all_unique_genes <- Reduce(union, list(
  signature_genes_SVM_10,
  signature_genes_SVM_100,
  signature_genes_SVM_1000,
  signature_genes_SVM_5000,
  signature_genes_SVM_10000,
  signature_genes_RF_10,
  signature_genes_RF_100,
  signature_genes_RF_1000,
  signature_genes_RF_5000,
  signature_genes_RF_10000, 
  signature_genes_LR_10,
  signature_genes_LR_100,
  signature_genes_LR_1000,
  signature_genes_LR_5000,
  signature_genes_LR_10000
))
```

1.  Extract a subset of the original gene expression dataframe which
    only has the selected signature genes.
2.  Adjust "reference group" dataframe to put samples in rownames
3.  Sort

```{r}
subsetAlignedToSignatureGenes <- expression_df[rownames(expression_df) %in% all_unique_genes, ]
subsetAlignedToSignatureGenes <- as.data.frame(subsetAlignedToSignatureGenes)

referenceGroup <- as.data.frame(referenceGroup)
rownames(referenceGroup) <- referenceGroup$refinebio_accession_code

referenceGroup$refinebio_accession_code <- NULL

subsetAlignedToSignatureGenes <- subsetAlignedToSignatureGenes[, rownames(referenceGroup)]

# Convert Diabetes Column to Factor
referenceGroup$diabetes <- as.factor(referenceGroup$diabetes)
ann_colors <- list(diabetes = c('0' = 'blue', '1' = 'red'))

# Reorder the gene expression frame to match order of samples in annotation data 
ordered_gene_df <- subsetAlignedToSignatureGenes[, rownames(referenceGroup)]
```

Below, two heatmaps are illustrated. The reason for this is that we have
been provided instructions to illustrate hierarchical clustering on both
axes but also to provide annotation data. We go to extra effort to order
this annotation data in hopes to see contrast on the heatmap that the
hierarchical clustering would override the sample order of (because it
is susceptible to trends in the provided gene vectors that are unrelated
to our target group of diabetics / nondiabetics). In order to ensure we
satisfy the conditions of the assignment we have therefore provided two
graphs, without and with clustering, to observe these differences.

PLEASE NOTE, we do not provide individual column labels as doing so proves
impractical. The font of the rows is intentionally small such that they do not
intersect making them legible at the rendered resolution.

```{r}
library(pheatmap)
library(grid)
setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")

pheatmap(ordered_gene_df,
         annotation_col = referenceGroup,
         annotation_colors = ann_colors,
         show_rownames = T,
         fontsize = 6,
         show_colnames = F, # Assuming sample names are not important for the heatmap
         clustering_distance_rows = "correlation",
         clustering_method = "complete",
         cluster_cols = F,
         scale = "row",
         width = 1920,
         height = 1080,
         color = colorRampPalette(c("black", "purple", "white"))(255), # Color scheme
         border_color = NA # No border for each cell,
)

setHook("grid.newpage", NULL, "replace")
grid.text("Sequences", y=-0.07, gp=gpar(fontsize=16))
grid.text("Genes", x=-0.07, rot=90, gp=gpar(fontsize=16))
```

```{r}
setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")

pheatmap(ordered_gene_df,
         annotation_col = referenceGroup,
         annotation_colors = ann_colors,
         show_rownames = T,
         fontsize = 6,
         show_colnames = F, # Assuming sample names are not important for the heatmap
         clustering_distance_rows = "correlation",
         clustering_method = "complete",
         cluster_cols = T,
         scale = "row",
         width = 1920,
         height = 1080,
         color = colorRampPalette(c("black", "purple", "white"))(255), # Color scheme
         border_color = NA # No border for each cell,
)
setHook("grid.newpage", NULL, "replace")
grid.text("Sequences", y=-0.07, gp=gpar(fontsize=16))
grid.text("Genes", x=-0.07, rot=90, gp=gpar(fontsize=16))
```



Admittedly the differences in the two heatmaps aren't very pronounced.
We scale the data by gene so as to visually present the expression Z
score of a gene relative to itself in adjacent samples. Hierarchical
clustering does visually present some contrast towards the right of the
graph, but our order-by-annotation version of the heatmap (first of the
two) is significantly less noteworthy in its trends. We assume that the
trends our various clustering algorithms identified were simply more
complex than easily made visible. That's to say, SVM likely discovered
not individual genes but combinations of genes which help discriminate a
sample, and visualizing this relies heavily on the order in which genes
are presented. We experimented with row clustering by correlation
(cosine / pearson) rather than euclidean distance and otherwise altering
the visualization (z scores within samples rather than within genes
accross samples) but still were unable to show any interesting contrast
between our columns of diabetics and nondiabetics in the first graph.\
\
If we were to make a more serious effort as researchers not to explore
various methods but to pick an optimal one, we'd attempt to tune the
hyperparameters of SVM after first performing PCA in order to identify
the most significant genes. We might then use euclidean distance to
reintroduce colinear but therefore related and significant genes to our
"signatures" and visualize these exclusively, as random forest and
logistic regression both perform very poorly by comparison.




#OVERLAP BETWEEN ALL 5000 GENES FOR THE METHODS
```{r}
vectors <- list(
  LR5000=signature_genes_LR_5000,
  RF5000=signature_genes_RF_5000,
  SVM5000=signature_genes_SVM_5000
)
  
# Initialize a matrix to store the fractions
overlap_matrix <- matrix(0, nrow = length(vectors), ncol = length(vectors))
# Calculate the fractions
for (i in 1:length(vectors)) {
  cat(names(vectors)[i], " signature gene #: ", length(vectors[[i]]), "\n")
  for (j in 1:length(vectors)) {
    if (i<j) {
      overlap_matrix[i,j]<-length(intersect(vectors[[i]], vectors[[j]])) / length(vectors[[i]])
    }
  }
}
cat("\n")
# Display the overlap matrix
rownames(overlap_matrix) <- colnames(overlap_matrix) <- c(
  "LR5000",
  "RF5000",
  "SVM5000")
print(overlap_matrix)
```
